From 74af717a0645f2bd68ea2cf1892ff12665de8ee9 Mon Sep 17 00:00:00 2001
From: Aleksei Greshilov <aleksei.greshilov@cern.ch>
Date: Fri, 13 Sep 2024 08:57:31 -0400
Subject: [PATCH] Static DMA Proxy & Xilinx XVC drivers fixes

---
 drivers/Kconfig                               |   3 +-
 drivers/Makefile                              |   4 +
 drivers/x2o/Kconfig                           |  26 +
 drivers/x2o/Makefile                          |   5 +
 drivers/x2o/dma-proxy/Makefile                |   3 +
 drivers/x2o/dma-proxy/dma-proxy.c             | 670 ++++++++++++++++++
 drivers/x2o/dma-proxy/dma-proxy.h             |  42 ++
 drivers/x2o/xilinx-xvc-driver/Makefile        |   5 +
 .../x2o/xilinx-xvc-driver/xilinx-xvc-driver.c | 182 +++++
 drivers/x2o/xilinx-xvc-driver/xvc_driver.c    | 207 ++++++
 drivers/x2o/xilinx-xvc-driver/xvc_driver.h    |  40 ++
 .../x2o/xilinx-xvc-driver/xvc_driver_base.c   | 278 ++++++++
 drivers/x2o/xilinx-xvc-driver/xvc_ioctl.h     |  44 ++
 .../x2o/xilinx-xvc-driver/xvc_user_config.h   |  95 +++
 14 files changed, 1603 insertions(+), 1 deletion(-)
 create mode 100644 drivers/x2o/Kconfig
 create mode 100644 drivers/x2o/Makefile
 create mode 100644 drivers/x2o/dma-proxy/Makefile
 create mode 100644 drivers/x2o/dma-proxy/dma-proxy.c
 create mode 100644 drivers/x2o/dma-proxy/dma-proxy.h
 create mode 100644 drivers/x2o/xilinx-xvc-driver/Makefile
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xilinx-xvc-driver.c
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xvc_driver.c
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xvc_driver.h
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xvc_driver_base.c
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xvc_ioctl.h
 create mode 100644 drivers/x2o/xilinx-xvc-driver/xvc_user_config.h

diff --git a/drivers/Kconfig b/drivers/Kconfig
index 0d399ddaa185..1fd9dc570385 100644
--- a/drivers/Kconfig
+++ b/drivers/Kconfig
@@ -3,6 +3,8 @@ menu "Device Drivers"
 
 # Keep I/O buses first
 
+source "drivers/x2o/Kconfig"
+
 source "drivers/amba/Kconfig"
 source "drivers/eisa/Kconfig"
 source "drivers/pci/Kconfig"
@@ -10,7 +12,6 @@ source "drivers/cxl/Kconfig"
 source "drivers/pcmcia/Kconfig"
 source "drivers/rapidio/Kconfig"
 
-
 source "drivers/base/Kconfig"
 
 source "drivers/bus/Kconfig"
diff --git a/drivers/Makefile b/drivers/Makefile
index a110338c860c..e8208bf3e905 100644
--- a/drivers/Makefile
+++ b/drivers/Makefile
@@ -5,6 +5,10 @@
 # 15 Sep 2000, Christoph Hellwig <hch@infradead.org>
 # Rewritten to use lists instead of if-statements.
 #
+# 27 Aug 2024, CERN, Aleksei Greshilov <aleksei.greshilov@cern.ch>
+# Added support for X2O platform.
+# X2O platform drivers.
+obj-y                           += x2o/
 
 obj-y				+= irqchip/
 obj-y				+= bus/
diff --git a/drivers/x2o/Kconfig b/drivers/x2o/Kconfig
new file mode 100644
index 000000000000..2d0c51dac14e
--- /dev/null
+++ b/drivers/x2o/Kconfig
@@ -0,0 +1,26 @@
+# X2O platform support
+#
+
+menuconfig X2O
+	default y
+	bool "X2O platform support"
+	help
+	  You can say N here if you don't intend to work with X2O platform. 
+
+# All the following symbols are dependent on X2O - do not repeat
+# that for each of the symbols.
+if X2O
+
+config XILINX_XVC
+	default y
+	bool "Enable Xilinx XVC driver"
+	help
+	  You can say N here if you don't intend to enable fast FPGA debugging driver via standard JTAG chain within X2O platform.
+
+config DMA_PROXY
+	default y
+	bool "Enable DMA Proxy driver"
+	help
+	  You can say N here if you don't intend to enable fast FPGA programming driver via DMA-JTAG chain within X2O platform.
+
+endif # X2O
diff --git a/drivers/x2o/Makefile b/drivers/x2o/Makefile
new file mode 100644
index 000000000000..634e69f0ec78
--- /dev/null
+++ b/drivers/x2o/Makefile
@@ -0,0 +1,5 @@
+# Makefile for the Linux X2O platform drivers.
+#
+
+obj-$(CONFIG_DMA_PROXY) += dma-proxy/
+obj-$(CONFIG_XILINX_XVC) += xilinx-xvc-driver/
diff --git a/drivers/x2o/dma-proxy/Makefile b/drivers/x2o/dma-proxy/Makefile
new file mode 100644
index 000000000000..21f2ece1e152
--- /dev/null
+++ b/drivers/x2o/dma-proxy/Makefile
@@ -0,0 +1,3 @@
+# Makefile for DMA Proxy driver.
+
+obj-$(CONFIG_DMA_PROXY) := dma-proxy.o
diff --git a/drivers/x2o/dma-proxy/dma-proxy.c b/drivers/x2o/dma-proxy/dma-proxy.c
new file mode 100644
index 000000000000..974b9aa4074c
--- /dev/null
+++ b/drivers/x2o/dma-proxy/dma-proxy.c
@@ -0,0 +1,670 @@
+/**
+ * Copyright (C) 2021 Xilinx, Inc
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License"). You may
+ * not use this file except in compliance with the License. A copy of the
+ * License is located at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+
+/* DMA Proxy
+ *
+ * This module is designed to be a small example of a DMA device driver that is
+ * a client to the DMA Engine using the AXI DMA / MCDMA driver. It serves as a proxy
+ * for kernel space DMA control to a user space application.
+ *
+ * A zero copy scheme is provided by allowing user space to mmap a kernel allocated
+ * memory region into user space, referred to as a set of channel buffers. Ioctl functions 
+ * are provided to start a DMA transfer (non-blocking), finish a DMA transfer (blocking) 
+ * previously started, or start and finish a DMA transfer blocking until it is complete.
+ * An input argument which specifies a channel buffer number (0 - N) to be used for the
+ * transfer is required.
+ *
+ * By default the kernel memory allocated for user space mapping is going to be 
+ * non-cached at this time. Non-cached memory is pretty slow for the application.
+ * A h/w coherent system for MPSOC has been tested and is recommended for higher
+ * performance applications. 
+ *
+ * Hardware coherency requires the following items in the system as documented on the 
+ * Xilinx wiki and summarized below::
+ *   The AXI DMA read and write channels AXI signals must be tied to the correct state to
+ *    generate coherent transactions.
+ *   An HPC slave port on MPSOC is required
+ *   The CCI of MPSOC must be initialized prior to the APU booting Linux
+ *   A dma-coherent property is added in the device tree for the proxy driver.
+ *
+ * There is an associated user space application, dma_proxy_test.c, and dma_proxy.h
+ * that works with this device driver.
+ *
+ * The hardware design was tested with an AXI DMA / MCDMA  with scatter gather and
+ * with the transmit channel looped back to the receive channel. It should
+ * work with or without scatter gather as the scatter gather mentioned in the 
+ * driver is only at the s/w framework level rather than in the hw.
+ *
+ * This driver is character driver which creates devices that user space can
+ * access for each DMA channel, such as /dev/dma_proxy_rx and /dev/dma_proxy_tx.
+ * The number and names of channels are taken from the device tree.
+ * Multiple instances of the driver (with multiple IPs) are also supported.
+
+ * An internal test mode is provided to allow it to be self testing without the 
+ * need for a user space application and this mode is good for making bigger
+ * changes to this driver.
+ *
+ * This driver is designed to be simple to help users get familiar with how to 
+ * use the DMA driver provided by Xilinx which uses the Linux DMA Engine. 
+ *
+ * To use this driver a node must be added into the device tree.  Add a 
+ * node similar to the examples below adjusting the dmas property to match the
+ * name of the AXI DMA / MCDMA node.
+ * 
+ * The dmas property contains pairs with the first of each pair being a reference
+ * to the DMA IP in the device tree and the second of each pair being the
+ * channel of the DMA IP. For the AXI DMA IP the transmit channel is always 0 and
+ * the receive is always 1. For the AXI MCDMA IP the 1st transmit channel is
+ * always 0 and receive channels start at 16 since there can be a maximum of 16
+ * transmit channels. Each name in the dma-names corresponds to a pair in the dmas
+ * property and is only a logical name that allows user space access to the channel
+ * such that the name can be any name as long as it is unique.
+ *
+ *	For h/w coherent systems with MPSoC, the property dma-coherent can be added
+ * to the node in the device tree. 
+ * 
+ * Example device tree nodes: 
+ *
+ * For AXI DMA with transmit and receive channels with a loopback in hardware
+ * 
+ * dma_proxy {
+ *   compatible ="xlnx,dma_proxy";
+ *   dmas = <&axi_dma_1_loopback 0  &axi_dma_1_loopback 1>;
+ *   dma-names = "dma_proxy_tx", "dma_proxy_rx";
+ * };
+ *
+ * For AXI DMA with only the receive channel
+ * 
+ * dma_proxy2 {
+ *   compatible ="xlnx,dma_proxy";
+ *   dmas = <&axi_dma_0_noloopback 1>;
+ *   dma-names = "dma_proxy_rx_only";
+ * };
+ *
+ * For AXI MCDMA with two channels 
+ *
+ * dma_proxy3 {
+ *   compatible ="xlnx,dma_proxy";
+ *   dmas = <&axi_mcdma_0 0  &axi_mcdma_0 16 &axi_mcdma_0 1 &axi_mcdma_0 17> ;
+ *   dma-names = "dma_proxy_tx_0", "dma_proxy_rx_0", "dma_proxy_tx_1", "dma_proxy_rx_1";
+ * };
+ */
+
+#include <linux/dmaengine.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/dma-mapping.h>
+#include <linux/slab.h>
+#include <linux/cdev.h>
+#include <linux/device.h>
+#include <linux/fs.h>
+#include <linux/workqueue.h>
+#include <linux/platform_device.h>
+#include <linux/of_dma.h>
+#include <linux/ioctl.h>
+#include <linux/uaccess.h>
+
+#include "dma-proxy.h"
+
+MODULE_LICENSE("GPL");
+
+#define DRIVER_NAME 			"dma_proxy"
+#define TX_CHANNEL			0
+#define RX_CHANNEL			1
+#define ERROR 					-1
+#define TEST_SIZE 			1024
+
+/* The following module parameter controls if the internal test runs when the module is inserted.
+ * Note that this test requires a transmit and receive channel to function and uses the first
+ * transmit and receive channnels when multiple channels exist.
+ */
+static unsigned internal_test = 0;
+module_param(internal_test, int, S_IRUGO);
+
+/* The following data structures represent a single channel of DMA, transmit or receive in the case
+ * when using AXI DMA.  It contains all the data to be maintained for the channel.
+ */
+struct proxy_bd {
+	struct completion cmp;
+	dma_cookie_t cookie;
+	dma_addr_t dma_handle;
+	struct scatterlist sglist;
+};
+struct dma_proxy_channel {
+	struct channel_buffer *buffer_table_p;	/* user to kernel space interface */
+	dma_addr_t buffer_phys_addr;
+
+	struct device *proxy_device_p;				/* character device support */
+	struct device *dma_device_p;
+	dev_t dev_node;
+	struct cdev cdev;
+	struct class *class_p;
+
+	struct proxy_bd bdtable[BUFFER_COUNT];
+
+	struct dma_chan *channel_p;				/* dma support */
+	u32 direction;						/* DMA_MEM_TO_DEV or DMA_DEV_TO_MEM */
+	int bdindex;
+};
+
+struct dma_proxy {
+	int channel_count;
+	struct dma_proxy_channel *channels;
+	char **names;
+	struct work_struct work;
+};
+
+static int total_count;
+
+/* Handle a callback and indicate the DMA transfer is complete to another
+ * thread of control
+ */
+static void sync_callback(void *completion)
+{
+	/* Indicate the DMA transaction completed to allow the other
+	 * thread of control to finish processing
+	 */
+	complete(completion);
+}
+
+/* Prepare a DMA buffer to be used in a DMA transaction, submit it to the DMA engine
+ * to ibe queued and return a cookie that can be used to track that status of the
+ * transaction
+ */
+static void start_transfer(struct dma_proxy_channel *pchannel_p)
+{
+	enum dma_ctrl_flags flags = DMA_CTRL_ACK | DMA_PREP_INTERRUPT;
+	struct dma_async_tx_descriptor *chan_desc;
+	struct dma_device *dma_device = pchannel_p->channel_p->device;
+	int bdindex = pchannel_p->bdindex;
+
+	/* A single entry scatter gather list is used as it's not clear how to do it with a simpler method.
+	 * Get a descriptor for the transfer ready to submit
+	 */
+	sg_init_table(&pchannel_p->bdtable[bdindex].sglist, 1);
+	sg_dma_address(&pchannel_p->bdtable[bdindex].sglist) = pchannel_p->bdtable[bdindex].dma_handle;
+	sg_dma_len(&pchannel_p->bdtable[bdindex].sglist) = pchannel_p->buffer_table_p[bdindex].length;
+
+	chan_desc = dma_device->device_prep_slave_sg(pchannel_p->channel_p, &pchannel_p->bdtable[bdindex].sglist, 1, 
+						pchannel_p->direction, flags, NULL);
+
+	if (!chan_desc) {
+		printk(KERN_ERR "dmaengine_prep*() error\n");
+	} else {
+		chan_desc->callback = sync_callback;
+		chan_desc->callback_param = &pchannel_p->bdtable[bdindex].cmp;
+
+		/* Initialize the completion for the transfer and before using it
+		 * then submit the transaction to the DMA engine so that it's queued
+		 * up to be processed later and get a cookie to track it's status
+		 */
+		init_completion(&pchannel_p->bdtable[bdindex].cmp);
+
+		pchannel_p->bdtable[bdindex].cookie = dmaengine_submit(chan_desc);
+		if (dma_submit_error(pchannel_p->bdtable[bdindex].cookie)) {
+			printk("Submit error\n");
+	 		return;
+		}
+
+		/* Start the DMA transaction which was previously queued up in the DMA engine
+		 */
+		dma_async_issue_pending(pchannel_p->channel_p);
+	}
+}
+
+/* Wait for a DMA transfer that was previously submitted to the DMA engine
+ */
+static void wait_for_transfer(struct dma_proxy_channel *pchannel_p)
+{
+	unsigned long timeout = msecs_to_jiffies(300000);
+	enum dma_status status;
+	int bdindex = pchannel_p->bdindex;
+
+	pchannel_p->buffer_table_p[bdindex].status = PROXY_BUSY;
+
+	/* Wait for the transaction to complete, or timeout, or get an error
+	 */
+	timeout = wait_for_completion_timeout(&pchannel_p->bdtable[bdindex].cmp, timeout);
+	status = dma_async_is_tx_complete(pchannel_p->channel_p, pchannel_p->bdtable[bdindex].cookie, NULL, NULL);
+
+	if (timeout == 0)  {
+		pchannel_p->buffer_table_p[bdindex].status  = PROXY_TIMEOUT;
+		printk(KERN_ERR "DMA timed out\n");
+	} else if (status != DMA_COMPLETE) {
+		pchannel_p->buffer_table_p[bdindex].status = PROXY_ERROR;
+		printk(KERN_ERR "DMA returned completion callback status of: %s\n",
+			   status == DMA_ERROR ? "error" : "in progress");
+	} else
+		pchannel_p->buffer_table_p[bdindex].status = PROXY_NO_ERROR;
+}
+
+/* The following functions are designed to test the driver from within the device
+ * driver without any user space. It uses the first channel buffer for the transmit and receive.
+ * If this works but the user application does not then the user application is at fault.
+ */
+static void tx_test(struct work_struct *local_work)
+{
+	struct dma_proxy *lp;
+	lp = container_of(local_work, struct dma_proxy, work);
+
+	/* Use the 1st buffer for the test
+	 */
+	lp->channels[TX_CHANNEL].buffer_table_p[0].length = TEST_SIZE;
+	lp->channels[TX_CHANNEL].bdindex = 0;
+
+	start_transfer(&lp->channels[TX_CHANNEL]);
+	wait_for_transfer(&lp->channels[TX_CHANNEL]);
+}
+
+static void test(struct dma_proxy *lp)
+{
+	int i;
+
+	printk("Starting internal test\n");
+
+	/* Initialize the buffers for the test
+	 */
+	for (i = 0; i < TEST_SIZE / sizeof(unsigned int); i++) {
+		lp->channels[TX_CHANNEL].buffer_table_p[0].buffer[i] = i;
+		lp->channels[RX_CHANNEL].buffer_table_p[0].buffer[i] = 0;
+	}
+
+	/* Since the transfer function is blocking the transmit channel is started from a worker
+	 * thread
+	 */
+	INIT_WORK(&lp->work, tx_test);
+	schedule_work(&lp->work);
+
+	/* Receive the data that was just sent and looped back
+	 */
+	lp->channels[RX_CHANNEL].buffer_table_p->length = TEST_SIZE;
+	lp->channels[TX_CHANNEL].bdindex = 0;
+
+	start_transfer(&lp->channels[RX_CHANNEL]);
+	wait_for_transfer(&lp->channels[RX_CHANNEL]);
+
+	/* Verify the receiver buffer matches the transmit buffer to
+	 * verify the transfer was good
+	 */
+	for (i = 0; i < TEST_SIZE / sizeof(unsigned int); i++)
+		if (lp->channels[TX_CHANNEL].buffer_table_p[0].buffer[i] !=
+			lp->channels[RX_CHANNEL].buffer_table_p[0].buffer[i]) {
+			printk("buffers not equal, first index = %d\n", i);
+			break;
+		}
+
+	printk("Internal test complete\n");
+}
+
+/* Map the memory for the channel interface into user space such that user space can
+ * access it using coherent memory which will be non-cached for s/w coherent systems
+ * such as Zynq 7K or the current default for Zynq MPSOC. MPSOC can be h/w coherent
+ * when set up and then the memory will be cached.
+ */
+static int mmap(struct file *file_p, struct vm_area_struct *vma)
+{
+	struct dma_proxy_channel *pchannel_p = (struct dma_proxy_channel *)file_p->private_data;
+
+	return dma_mmap_coherent(pchannel_p->dma_device_p, vma,
+					   pchannel_p->buffer_table_p, pchannel_p->buffer_phys_addr,
+					   vma->vm_end - vma->vm_start);
+}
+
+/* Open the device file and set up the data pointer to the proxy channel data for the
+ * proxy channel such that the ioctl function can access the data structure later.
+ */
+static int local_open(struct inode *ino, struct file *file)
+{
+	file->private_data = container_of(ino->i_cdev, struct dma_proxy_channel, cdev);
+
+	return 0;
+}
+
+/* Close the file and there's nothing to do for it
+ */
+static int release(struct inode *ino, struct file *file)
+{
+	struct dma_proxy_channel *pchannel_p = (struct dma_proxy_channel *)file->private_data;
+	struct dma_device *dma_device = pchannel_p->channel_p->device;
+
+	/* Stop all the activity when the channel is closed assuming this
+	 * may help if the application is aborted without normal closure
+	 * This is not working and causes an issue that may need investigation in the 
+	 * DMA driver at the lower level.
+	 */
+#if 0
+	dma_device->device_terminate_all(pchannel_p->channel_p);
+#endif
+	return 0;
+}
+
+/* Perform I/O control to perform a DMA transfer using the input as an index
+ * into the buffer descriptor table such that the application is in control of
+ * which buffer to use for the transfer.The BD in this case is only a s/w
+ * structure for the proxy driver, not related to the hw BD of the DMA.
+ */
+static long ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct dma_proxy_channel *pchannel_p = (struct dma_proxy_channel *)file->private_data;
+	dma_addr_t test;
+
+	/* Get the bd index from the input argument as all commands require it
+	 */
+	copy_from_user(&pchannel_p->bdindex, (int *)arg, sizeof(pchannel_p->bdindex)); 
+
+	/* Perform the DMA transfer on the specified channel blocking til it completes
+	 */
+	switch(cmd) {
+		case START_XFER:
+			start_transfer(pchannel_p);
+			break;
+		case FINISH_XFER:
+			wait_for_transfer(pchannel_p);
+			break;
+		case XFER:
+			start_transfer(pchannel_p);
+			wait_for_transfer(pchannel_p);
+			break;
+	}
+
+	return 0;
+}
+
+static struct file_operations dm_fops = {
+	.owner    = THIS_MODULE,
+	.open     = local_open,
+	.release  = release,
+	.unlocked_ioctl = ioctl,
+	.mmap	= mmap
+};
+
+
+/* Initialize the driver to be a character device such that is responds to
+ * file operations.
+ */
+static int cdevice_init(struct dma_proxy_channel *pchannel_p, char *name)
+{
+	int rc;
+	char device_name[32] = "dma_proxy";
+	static struct class *local_class_p = NULL;
+
+	/* Allocate a character device from the kernel for this driver.
+	 */
+	rc = alloc_chrdev_region(&pchannel_p->dev_node, 0, 1, "dma_proxy");
+
+	if (rc) {
+		dev_err(pchannel_p->dma_device_p, "unable to get a char device number\n");
+		return rc;
+	}
+
+	/* Initialize the device data structure before registering the character 
+	 * device with the kernel.
+	 */
+	cdev_init(&pchannel_p->cdev, &dm_fops);
+	pchannel_p->cdev.owner = THIS_MODULE;
+	rc = cdev_add(&pchannel_p->cdev, pchannel_p->dev_node, 1);
+
+	if (rc) {
+		dev_err(pchannel_p->dma_device_p, "unable to add char device\n");
+		goto init_error1;
+	}
+
+	/* Only one class in sysfs is to be created for multiple channels,
+	 * create the device in sysfs which will allow the device node
+	 * in /dev to be created
+	 */
+	if (!local_class_p) {
+		local_class_p = class_create(THIS_MODULE, DRIVER_NAME);
+
+		if (IS_ERR(pchannel_p->dma_device_p->class)) {
+			dev_err(pchannel_p->dma_device_p, "unable to create class\n");
+			rc = ERROR;
+			goto init_error2;
+		}
+	}
+	pchannel_p->class_p = local_class_p;
+
+	/* Create the device node in /dev so the device is accessible
+	 * as a character device
+	 */
+	strcat(device_name, name);
+	pchannel_p->proxy_device_p = device_create(pchannel_p->class_p, NULL,
+					  	 pchannel_p->dev_node, NULL, name);
+
+	if (IS_ERR(pchannel_p->proxy_device_p)) {
+		dev_err(pchannel_p->dma_device_p, "unable to create the device\n");
+		goto init_error3;
+	}
+
+	return 0;
+
+init_error3:
+	class_destroy(pchannel_p->class_p);
+
+init_error2:
+	cdev_del(&pchannel_p->cdev);
+
+init_error1:
+	unregister_chrdev_region(pchannel_p->dev_node, 1);
+	return rc;
+}
+
+/* Exit the character device by freeing up the resources that it created and
+ * disconnecting itself from the kernel.
+ */
+static void cdevice_exit(struct dma_proxy_channel *pchannel_p)
+{
+	/* Take everything down in the reverse order
+	 * from how it was created for the char device
+	 */
+	if (pchannel_p->proxy_device_p) {
+		device_destroy(pchannel_p->class_p, pchannel_p->dev_node);
+
+		/* If this is the last channel then get rid of the /sys/class/dma_proxy
+		 */
+		if (total_count == 1)
+			class_destroy(pchannel_p->class_p);
+
+		cdev_del(&pchannel_p->cdev);
+		unregister_chrdev_region(pchannel_p->dev_node, 1);
+	}
+}
+
+/* Create a DMA channel by getting a DMA channel from the DMA Engine and then setting
+ * up the channel as a character device to allow user space control.
+ */
+static int create_channel(struct platform_device *pdev, struct dma_proxy_channel *pchannel_p, char *name, u32 direction)
+{
+	int rc, bd;
+
+	/* Request the DMA channel from the DMA engine and then use the device from
+	 * the channel for the proxy channel also.
+	 */
+	pchannel_p->channel_p = dma_request_slave_channel(&pdev->dev, name);
+	if (!pchannel_p->channel_p) {
+		dev_err(pchannel_p->dma_device_p, "DMA channel request error\n");
+		return ERROR;
+	}
+	pchannel_p->dma_device_p = &pdev->dev; 
+
+	/* Initialize the character device for the dma proxy channel
+	 */
+	rc = cdevice_init(pchannel_p, name);
+	if (rc) 
+		return rc;
+
+	pchannel_p->direction = direction;
+
+	/* Allocate DMA memory that will be shared/mapped by user space, allocating
+	 * a set of buffers for the channel with user space specifying which buffer
+	 * to use for a tranfer..
+	 */
+	pchannel_p->buffer_table_p = (struct channel_buffer *)
+		dmam_alloc_coherent(pchannel_p->dma_device_p,
+					sizeof(struct channel_buffer) * BUFFER_COUNT,
+					&pchannel_p->buffer_phys_addr, GFP_KERNEL);
+	printk(KERN_INFO "Allocating memory, virtual address: %016X physical address: %016X\n", 
+			pchannel_p->buffer_table_p, (void *)pchannel_p->buffer_phys_addr);
+
+	/* Initialize each entry in the buffer descriptor table such that the physical address	
+	 * address of each buffer is ready to use later.
+	 */
+	for (bd = 0; bd < BUFFER_COUNT; bd++) 
+		pchannel_p->bdtable[bd].dma_handle = (dma_addr_t)(pchannel_p->buffer_phys_addr + 
+						(sizeof(struct channel_buffer) * bd) + offsetof(struct channel_buffer, buffer));
+
+	/* The buffer descriptor index into the channel buffers should be specified in each 
+	 * ioctl but we will initialize it to be safe.
+	 */
+	pchannel_p->bdindex = 0;
+	if (!pchannel_p->buffer_table_p) {
+		dev_err(pchannel_p->dma_device_p, "DMA allocation error\n");
+		return ERROR;
+	}
+	return 0;
+}
+/* Initialize the dma proxy device driver module.
+ */
+static int dma_proxy_probe(struct platform_device *pdev)
+{
+	int rc, i;
+	struct dma_proxy *lp;
+	struct device *dev = &pdev->dev;
+
+	printk(KERN_INFO "dma_proxy module initialized\n");
+	
+	lp = (struct dma_proxy *) devm_kmalloc(&pdev->dev, sizeof(struct dma_proxy), GFP_KERNEL);
+	if (!lp) {
+		dev_err(dev, "Cound not allocate proxy device\n");
+		return -ENOMEM;
+	}
+	dev_set_drvdata(dev, lp);
+
+	/* Figure out how many channels there are from the device tree based
+	 * on the number of strings in the dma-names property
+	 */
+	lp->channel_count = device_property_read_string_array(&pdev->dev,
+						 "dma-names", NULL, 0);
+	if (lp->channel_count <= 0)
+		return 0;
+
+	printk("Device Tree Channel Count: %d\r\n", lp->channel_count);
+
+	/* Allocate the memory for channel names and then get the names
+    * from the device tree
+	 */
+	lp->names = devm_kmalloc_array(&pdev->dev, lp->channel_count, 
+			sizeof(char *), GFP_KERNEL);
+	if (!lp->names)
+		return -ENOMEM;
+
+	rc = device_property_read_string_array(&pdev->dev, "dma-names", 
+					(const char **)lp->names, lp->channel_count);
+	if (rc < 0)
+		return rc;
+	
+	/* Allocate the memory for the channels since the number is known.
+	 */
+	lp->channels = devm_kmalloc(&pdev->dev,
+			sizeof(struct dma_proxy_channel) * lp->channel_count, GFP_KERNEL);
+	if (!lp->channels)
+		return -ENOMEM;
+
+	/* Create the channels in the proxy. The direction does not matter
+	 * as the DMA channel has it inside it and uses it, other than this will not work 
+	 * for cyclic mode.
+	 */
+	for (i = 0; i < lp->channel_count; i++) {
+		printk("Creating channel %s\r\n", lp->names[i]);
+		rc = create_channel(pdev, &lp->channels[i], lp->names[i], DMA_MEM_TO_DEV);
+
+		if (rc < 0) 
+			return -EPROBE_DEFER;
+
+		if (rc) 
+			return rc;
+		total_count++;
+	}
+
+	if (internal_test)
+		test(lp);
+	return 0;
+}
+ 
+/* Exit the dma proxy device driver module.
+ */
+static int dma_proxy_remove(struct platform_device *pdev)
+{
+	int i;
+	struct device *dev = &pdev->dev;
+	struct dma_proxy *lp = dev_get_drvdata(dev);
+
+	printk(KERN_INFO "dma_proxy module exited\n");
+
+	/* Take care of the char device infrastructure for each
+	 * channel except for the last channel. Handle the last
+	 * channel seperately.
+	 */
+	for (i = 0; i < lp->channel_count; i++) { 
+		if (lp->channels[i].proxy_device_p)
+			cdevice_exit(&lp->channels[i]);
+		total_count--;
+	}
+	/* Take care of the DMA channels and any buffers allocated
+	 * for the DMA transfers. The DMA buffers are using managed
+	 * memory such that it's automatically done.
+	 */
+	for (i = 0; i < lp->channel_count; i++)
+		if (lp->channels[i].channel_p) {
+			lp->channels[i].channel_p->device->device_terminate_all(lp->channels[i].channel_p);
+			dma_release_channel(lp->channels[i].channel_p);
+		}
+	return 0;
+}
+
+static const struct of_device_id dma_proxy_of_ids[] = {
+	{ .compatible = "xlnx,dma_proxy",},
+	{}
+};
+
+static struct platform_driver dma_proxy_driver = {
+	.driver = {
+		.name = "dma_proxy_driver",
+		.owner = THIS_MODULE,
+		.of_match_table = dma_proxy_of_ids,
+	},
+	.probe = dma_proxy_probe,
+	.remove = dma_proxy_remove,
+};
+
+static int __init dma_proxy_init(void)
+{
+	return platform_driver_register(&dma_proxy_driver);
+
+}
+
+static void __exit dma_proxy_exit(void)
+{
+	platform_driver_unregister(&dma_proxy_driver);
+}
+
+module_init(dma_proxy_init)
+module_exit(dma_proxy_exit)
+
+MODULE_AUTHOR("Xilinx, Inc.");
+MODULE_DESCRIPTION("DMA Proxy Prototype");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/x2o/dma-proxy/dma-proxy.h b/drivers/x2o/dma-proxy/dma-proxy.h
new file mode 100644
index 000000000000..5668f36bfbed
--- /dev/null
+++ b/drivers/x2o/dma-proxy/dma-proxy.h
@@ -0,0 +1,42 @@
+/**
+ * Copyright (C) 2021 Xilinx, Inc
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License"). You may
+ * not use this file except in compliance with the License. A copy of the
+ * License is located at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+ * License for the specific language governing permissions and limitations
+ * under the License.
+ */
+ /* This header file is shared between the DMA Proxy test application and the DMA Proxy device driver. It defines the
+ * shared interface to allow DMA transfers to be done from user space.
+ *
+ * A set of channel buffers are created by the driver for the transmit and receive channel. The application may choose
+ * to use only a subset of the channel buffers to allow prioritization of transmit vs receive.
+ *
+ * Note: the buffer in the data structure should be 1st in the channel interface so that the buffer is cached aligned,
+ * otherwise there may be issues when using cached memory.
+ */
+
+#define BUFFER_SIZE (128 * 1024)	 	/* must match driver exactly */
+//#define BUFFER_SIZE (64 * 1024)
+#define BUFFER_COUNT 32					/* driver only */
+
+#define TX_BUFFER_COUNT 	1				/* app only, must be <= to the number in the driver */
+#define RX_BUFFER_COUNT 	32				/* app only, must be <= to the number in the driver */
+#define BUFFER_INCREMENT	1				/* normally 1, but skipping buffers (2) defeats prefetching in the CPU */
+
+#define FINISH_XFER 	_IOW('a','a',int32_t*)
+#define START_XFER 		_IOW('a','b',int32_t*)
+#define XFER 			_IOR('a','c',int32_t*)
+
+struct channel_buffer {
+	unsigned int buffer[BUFFER_SIZE / sizeof(unsigned int)];
+	enum proxy_status { PROXY_NO_ERROR = 0, PROXY_BUSY = 1, PROXY_TIMEOUT = 2, PROXY_ERROR = 3 } status;
+	unsigned int length;
+} __attribute__ ((aligned (1024)));		/* 64 byte alignment required for DMA, but 1024 handy for viewing memory */
diff --git a/drivers/x2o/xilinx-xvc-driver/Makefile b/drivers/x2o/xilinx-xvc-driver/Makefile
new file mode 100644
index 000000000000..092971601b4c
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/Makefile
@@ -0,0 +1,5 @@
+# Makefile for Xilinx XVC driver.
+
+obj-$(CONFIG_XILINX_XVC) := xilinx-xvc-driver.o
+xilinx-xvc-driver-$(CONFIG_XILINX_XVC) += xvc_driver_base.o
+xilinx-xvc-driver-$(CONFIG_XILINX_XVC) += xvc_driver.o
diff --git a/drivers/x2o/xilinx-xvc-driver/xilinx-xvc-driver.c b/drivers/x2o/xilinx-xvc-driver/xilinx-xvc-driver.c
new file mode 100644
index 000000000000..fca272fcfbc5
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xilinx-xvc-driver.c
@@ -0,0 +1,182 @@
+/*  xilinx-xvc-driver.c - The simplest kernel module.
+
+* Copyright (C) 2013 - 2016 Xilinx, Inc
+*
+*   This program is free software; you can redistribute it and/or modify
+*   it under the terms of the GNU General Public License as published by
+*   the Free Software Foundation; either version 2 of the License, or
+*   (at your option) any later version.
+
+*   This program is distributed in the hope that it will be useful,
+*   but WITHOUT ANY WARRANTY; without even the implied warranty of
+*   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+*   GNU General Public License for more details.
+*
+*   You should have received a copy of the GNU General Public License along
+*   with this program. If not, see <http://www.gnu.org/licenses/>.
+
+*/
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/io.h>
+#include <linux/interrupt.h>
+
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/of_platform.h>
+
+/* Standard module information, edit as appropriate */
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR
+    ("Xilinx Inc.");
+MODULE_DESCRIPTION
+    ("xilinx-xvc-driver - loadable module template generated by petalinux-create -t modules");
+
+#define DRIVER_NAME "xilinx-xvc-driver"
+
+/* Simple example of how to receive command line parameters to your module.
+   Delete if you don't need them */
+unsigned myint = 0xdeadbeef;
+char *mystr = "default";
+
+module_param(myint, int, S_IRUGO);
+module_param(mystr, charp, S_IRUGO);
+
+struct xilinx_xvc_driver_local {
+	int irq;
+	unsigned long mem_start;
+	unsigned long mem_end;
+	void __iomem *base_addr;
+};
+
+static irqreturn_t xilinx_xvc_driver_irq(int irq, void *lp)
+{
+	printk("xilinx-xvc-driver interrupt\n");
+	return IRQ_HANDLED;
+}
+
+static int xilinx_xvc_driver_probe(struct platform_device *pdev)
+{
+	struct resource *r_irq; /* Interrupt resources */
+	struct resource *r_mem; /* IO mem resources */
+	struct device *dev = &pdev->dev;
+	struct xilinx_xvc_driver_local *lp = NULL;
+
+	int rc = 0;
+	dev_info(dev, "Device Tree Probing\n");
+	/* Get iospace for the device */
+	r_mem = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+	if (!r_mem) {
+		dev_err(dev, "invalid address\n");
+		return -ENODEV;
+	}
+	lp = (struct xilinx_xvc_driver_local *) kmalloc(sizeof(struct xilinx_xvc_driver_local), GFP_KERNEL);
+	if (!lp) {
+		dev_err(dev, "Cound not allocate xilinx-xvc-driver device\n");
+		return -ENOMEM;
+	}
+	dev_set_drvdata(dev, lp);
+	lp->mem_start = r_mem->start;
+	lp->mem_end = r_mem->end;
+
+	if (!request_mem_region(lp->mem_start,
+				lp->mem_end - lp->mem_start + 1,
+				DRIVER_NAME)) {
+		dev_err(dev, "Couldn't lock memory region at %p\n",
+			(void *)lp->mem_start);
+		rc = -EBUSY;
+		goto error1;
+	}
+
+	lp->base_addr = ioremap(lp->mem_start, lp->mem_end - lp->mem_start + 1);
+	if (!lp->base_addr) {
+		dev_err(dev, "xilinx-xvc-driver: Could not allocate iomem\n");
+		rc = -EIO;
+		goto error2;
+	}
+
+	/* Get IRQ for the device */
+	r_irq = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+	if (!r_irq) {
+		dev_info(dev, "no IRQ found\n");
+		dev_info(dev, "xilinx-xvc-driver at 0x%08x mapped to 0x%08x\n",
+			(unsigned int __force)lp->mem_start,
+			(unsigned int __force)lp->base_addr);
+		return 0;
+	}
+	lp->irq = r_irq->start;
+	rc = request_irq(lp->irq, &xilinx_xvc_driver_irq, 0, DRIVER_NAME, lp);
+	if (rc) {
+		dev_err(dev, "testmodule: Could not allocate interrupt %d.\n",
+			lp->irq);
+		goto error3;
+	}
+
+	dev_info(dev,"xilinx-xvc-driver at 0x%08x mapped to 0x%08x, irq=%d\n",
+		(unsigned int __force)lp->mem_start,
+		(unsigned int __force)lp->base_addr,
+		lp->irq);
+	return 0;
+error3:
+	free_irq(lp->irq, lp);
+error2:
+	release_mem_region(lp->mem_start, lp->mem_end - lp->mem_start + 1);
+error1:
+	kfree(lp);
+	dev_set_drvdata(dev, NULL);
+	return rc;
+}
+
+static int xilinx_xvc_driver_remove(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct xilinx_xvc_driver_local *lp = dev_get_drvdata(dev);
+	free_irq(lp->irq, lp);
+	iounmap(lp->base_addr);
+	release_mem_region(lp->mem_start, lp->mem_end - lp->mem_start + 1);
+	kfree(lp);
+	dev_set_drvdata(dev, NULL);
+	return 0;
+}
+
+#ifdef CONFIG_OF
+static struct of_device_id xilinx_xvc_driver_of_match[] = {
+	{ .compatible = "vendor,xilinx-xvc-driver", },
+	{ /* end of list */ },
+};
+MODULE_DEVICE_TABLE(of, xilinx_xvc_driver_of_match);
+#else
+# define xilinx_xvc_driver_of_match
+#endif
+
+
+static struct platform_driver xilinx_xvc_driver_driver = {
+	.driver = {
+		.name = DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.of_match_table	= xilinx_xvc_driver_of_match,
+	},
+	.probe		= xilinx_xvc_driver_probe,
+	.remove		= xilinx_xvc_driver_remove,
+};
+
+static int __init xilinx_xvc_driver_init(void)
+{
+	printk("<1>Hello module world.\n");
+	printk("<1>Module parameters were (0x%08x) and \"%s\"\n", myint,
+	       mystr);
+
+	return platform_driver_register(&xilinx_xvc_driver_driver);
+}
+
+
+static void __exit xilinx_xvc_driver_exit(void)
+{
+	platform_driver_unregister(&xilinx_xvc_driver_driver);
+	printk(KERN_ALERT "Goodbye module world.\n");
+}
+
+module_init(xilinx_xvc_driver_init);
+module_exit(xilinx_xvc_driver_exit);
diff --git a/drivers/x2o/xilinx-xvc-driver/xvc_driver.c b/drivers/x2o/xilinx-xvc-driver/xvc_driver.c
new file mode 100644
index 000000000000..71217f017691
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xvc_driver.c
@@ -0,0 +1,207 @@
+/*
+ * Xilinx XVC Driver
+ * Copyright (C) 2019 Xilinx Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/slab.h>
+#include <asm/uaccess.h>
+#include <linux/spinlock.h>
+#include <linux/platform_device.h>
+#include <linux/list.h>
+#include <linux/uaccess.h>
+//#include <asm-generic/io.h>
+#include <asm/io.h>
+
+#include "xvc_driver.h"
+
+#define LENGTH_REG_OFFSET   (0)
+#define TMS_REG_OFFSET      (4)
+#define TDI_REG_OFFSET      (8)
+#define TDO_REG_OFFSET      (12)
+#define CONTROL_REG_OFFSET  (16)
+
+static int xil_xvc_shift_bits(unsigned char* db_ptr, u32 tms_bits, u32 tdi_bits, u32 *tdo_bits) {
+	int status = 0;
+	u32 control_reg_data;
+	u32 write_reg_data;
+	int count = 200;
+
+	// Set tms bits
+	iowrite32(tms_bits, db_ptr + TMS_REG_OFFSET);
+
+	// Set tdi bits and shift data out
+	iowrite32(tdi_bits, db_ptr + TDI_REG_OFFSET);
+
+	// Read control register
+	control_reg_data = ioread32(db_ptr + CONTROL_REG_OFFSET);
+
+	// Enable shift operation in control register
+	write_reg_data = control_reg_data | 0x01;
+
+	// Write control register
+	iowrite32(write_reg_data, db_ptr + CONTROL_REG_OFFSET);
+
+	while (count) {
+		// Read control reg to check shift operation completion
+		control_reg_data = ioread32(db_ptr + CONTROL_REG_OFFSET);
+		if ((control_reg_data & 0x01) == 0)	{
+			break;
+		}
+		count--;
+	}
+	if (count == 0)	{
+		//printk(KERN_ERR LOG_PREFIX "XVC transaction timed out (%0X)\n", control_reg_data);
+		printk(KERN_ERR "XVC transaction timed out (%0X)\n", control_reg_data);
+		return -ETIMEDOUT;
+	}
+
+	// Read tdo bits back out
+	*tdo_bits = ioread32(db_ptr + TDO_REG_OFFSET);
+
+	return status;
+}
+
+long xil_xvc_ioctl(unsigned char* db_ptr, const char __user *arg) {
+	struct xil_xvc_ioc xvc_obj;
+	u32 operation_code;
+	u32 num_bits;
+	int num_bytes;
+	char *tms_buf_temp = NULL;
+	char *tdi_buf_temp = NULL;
+	char *tdo_buf_temp = NULL;
+	int current_bit;
+	u32 bypass_status;
+	long status = 0;
+
+	if ((status = copy_from_user((void *)&xvc_obj, arg, sizeof(struct xil_xvc_ioc)))) {
+		goto cleanup;
+	}
+
+	operation_code = xvc_obj.opcode;
+
+	// Invalid operation type, no operation performed
+	if (operation_code != 0x01 && operation_code != 0x02) {
+		return 0;
+	}
+
+	num_bits = xvc_obj.length;
+	num_bytes = (num_bits + 7) / 8;
+
+	// Allocate and copy data into temporary buffers
+	tms_buf_temp = (char*) kmalloc(num_bytes, GFP_KERNEL);
+	if (tms_buf_temp == NULL) {
+		status = -ENOMEM;
+		goto cleanup;
+	}
+	if ((status = copy_from_user((void *)tms_buf_temp, xvc_obj.tms_buf, num_bytes))) {
+		goto cleanup;
+	}
+
+	tdi_buf_temp = (char*) kmalloc(num_bytes, GFP_KERNEL);
+	if (tdi_buf_temp == NULL) {
+		status = -ENOMEM;
+		goto cleanup;
+	}
+	if ((status = copy_from_user((void *)tdi_buf_temp, xvc_obj.tdi_buf, num_bytes))) {
+		goto cleanup;
+	}
+
+	// Allocate TDO buffer
+	tdo_buf_temp = (char*) kmalloc(num_bytes, GFP_KERNEL);
+	if (tdo_buf_temp == NULL) {
+		status = -ENOMEM;
+		goto cleanup;
+	}
+
+	if (operation_code == 0x2) {
+		bypass_status = 0x2;
+	} else {
+		bypass_status = 0x0;
+	}
+
+	iowrite32(bypass_status, db_ptr + CONTROL_REG_OFFSET);
+
+	// Set length register to 32 initially if more than one word-transaction is to be done
+	if (num_bits >= 32) {
+		iowrite32(0x20, db_ptr + LENGTH_REG_OFFSET);
+	}
+
+	current_bit = 0;
+	while (current_bit < num_bits) {
+		int shift_num_bytes;
+		int shift_num_bits = 32;
+
+		u32 tms_store = 0;
+		u32 tdi_store = 0;
+		u32 tdo_store = 0;
+
+		if (num_bits - current_bit < shift_num_bits) {
+			shift_num_bits = num_bits - current_bit;
+			// do LENGTH_REG_OFFSET here
+			// Set number of bits to shift out
+			iowrite32(shift_num_bits, db_ptr + LENGTH_REG_OFFSET);
+		}
+
+		// Copy only the remaining number of bytes out of user-space
+		shift_num_bytes = (shift_num_bits + 7) / 8;
+
+		memcpy(&tms_store, tms_buf_temp + (current_bit / 8), shift_num_bytes);
+		memcpy(&tdi_store, tdi_buf_temp + (current_bit / 8), shift_num_bytes);
+
+		// Shift data out and copy to output buffer
+		status = xil_xvc_shift_bits(db_ptr, tms_store, tdi_store, &tdo_store);
+		if (status) {
+			goto cleanup;
+		}
+
+		memcpy(tdo_buf_temp + (current_bit / 8), &tdo_store, shift_num_bytes);
+
+		current_bit += shift_num_bits;
+	}
+
+	if (copy_to_user((void *)xvc_obj.tdo_buf, tdo_buf_temp, num_bytes)) {
+		status = -EFAULT;
+		goto cleanup;
+	}
+
+cleanup:
+	if (tms_buf_temp) kfree(tms_buf_temp);
+	if (tdi_buf_temp) kfree(tdi_buf_temp);
+	if (tdo_buf_temp) kfree(tdo_buf_temp);
+	return status;
+}
+
+long xil_xvc_readprops(const struct db_config* db_config, const char __user* arg) {
+	struct xil_xvc_properties xvc_props_obj;
+
+	if (!db_config) {
+		return -EINVAL;
+	}
+
+	xvc_props_obj.debug_bridge_base_addr = db_config->base_addr;
+	xvc_props_obj.debug_bridge_size = db_config->size;
+	strcpy(xvc_props_obj.debug_bridge_compat_string, DEBUG_BRIDGE_COMPAT_STRING);
+
+	if (copy_to_user((void *)arg, &xvc_props_obj, sizeof(xvc_props_obj))) {
+		return -ENOMEM;
+	}
+
+	return 0;
+}
diff --git a/drivers/x2o/xilinx-xvc-driver/xvc_driver.h b/drivers/x2o/xilinx-xvc-driver/xvc_driver.h
new file mode 100644
index 000000000000..8264502b66c0
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xvc_driver.h
@@ -0,0 +1,40 @@
+/*
+ * Xilinx XVC Driver
+ * Copyright (C) 2019 Xilinx Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#ifndef _XVC_DRIVER_H
+#define _XVC_DRIVER_H
+
+#include "xvc_ioctl.h"
+#include "xvc_user_config.h"
+
+#ifndef _XVC_USER_CONFIG_H
+#define XVC_DRIVER_NAME "xilinx_xvc_driver"
+#define DEBUG_BRIDGE_COMPAT_STRING "xlnx,xvc"
+// debug bridge configuration
+struct db_config {
+	const char* name;
+	unsigned long base_addr;
+	unsigned long size;
+};
+#endif
+
+long xil_xvc_ioctl(unsigned char* db_ptr, const char __user* arg);
+long xil_xvc_readprops(const struct db_config* db_config, const char __user* arg);
+
+#endif /* _XVC_DRIVER_H */
diff --git a/drivers/x2o/xilinx-xvc-driver/xvc_driver_base.c b/drivers/x2o/xilinx-xvc-driver/xvc_driver_base.c
new file mode 100644
index 000000000000..3b3aca996e15
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xvc_driver_base.c
@@ -0,0 +1,278 @@
+/*
+ * Xilinx XVC Driver
+ * Copyright (C) 2019 Xilinx Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/cdev.h>
+#include <linux/slab.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/kernel.h>
+#include <asm/io.h>
+#include <linux/mod_devicetable.h>
+
+#include "xvc_driver.h"
+#include "xvc_user_config.h"
+
+MODULE_LICENSE("GPL v2");
+MODULE_AUTHOR("Max Heimer <maxh@xilinx.com>");
+MODULE_DESCRIPTION("XVC Debug Register Access");
+MODULE_VERSION("0.1.0");
+
+static dev_t xvc_ioc_dev_region;
+static struct class* xvc_dev_class = NULL;
+static struct cdev xvc_char_ioc_dev;
+
+#ifndef _XVC_USER_CONFIG_H
+#define CONFIG_COUNT 1
+#define GET_DB_BY_RES 1
+static struct resource *db_res = NULL;
+#endif /* _XVC_USER_CONFIG_H */
+
+static void __iomem * db_ptrs[CONFIG_COUNT];
+
+static void xil_xvc_cleanup(void) {
+	//printk(KERN_INFO LOG_PREFIX "Cleaning up resources...\n");
+	printk(KERN_INFO "Cleaning up resources...\n");
+
+	if (!IS_ERR(xvc_dev_class)) {
+		class_destroy(xvc_dev_class);
+		xvc_dev_class = NULL;
+		if (xvc_char_ioc_dev.owner != NULL) {
+			cdev_del(&xvc_char_ioc_dev);
+		}
+		unregister_chrdev_region(xvc_ioc_dev_region, CONFIG_COUNT);
+	}
+}
+
+long char_ctrl_ioctl(struct file *file_p, unsigned int cmd, unsigned long arg) {
+	long status = 0;
+	unsigned long irqflags = 0;
+	int char_index = iminor(file_p->f_path.dentry->d_inode) - MINOR(xvc_ioc_dev_region);
+
+	spin_lock_irqsave(&file_p->f_path.dentry->d_inode->i_lock, irqflags);
+
+	switch (cmd) {
+		case XDMA_IOCXVC:
+			status = xil_xvc_ioctl((unsigned char*)(db_ptrs[char_index]), (void __user *)arg);
+			break;
+		case XDMA_RDXVC_PROPS:
+			{
+#ifndef GET_DB_BY_RES
+				struct db_config config_info = db_configs[char_index];
+#else
+				struct db_config config_info = {
+					.name = NULL,
+					.base_addr = db_res ? db_res->start : 0,
+					.size = db_res ? resource_size(db_res) : 0,
+				};
+#endif
+				status = xil_xvc_readprops(&config_info, (void __user*)arg);
+				break;
+			}
+		default:
+			status = -ENOIOCTLCMD;
+			break;
+	}
+
+	//mmiowb();
+	spin_unlock_irqrestore(&file_p->f_path.dentry->d_inode->i_lock, irqflags);
+
+	return status;
+}
+
+static struct file_operations xil_xvc_ioc_ops = {
+	.owner = THIS_MODULE,
+	.unlocked_ioctl = char_ctrl_ioctl
+};
+
+int probe(struct platform_device* pdev) {
+	int status;
+	int i;
+	unsigned int use_index = CONFIG_COUNT > 1;
+	dev_t ioc_device_number;
+	char ioc_device_name[32];
+	struct device* xvc_ioc_device = NULL;
+
+	if (!xvc_dev_class) {
+		xvc_dev_class = class_create(THIS_MODULE, XVC_DRIVER_NAME);
+		if (IS_ERR(xvc_dev_class)) {
+			xil_xvc_cleanup();
+			dev_err(&pdev->dev, "unable to create class\n");
+			return PTR_ERR(xvc_dev_class);
+		}
+
+		cdev_init(&xvc_char_ioc_dev, &xil_xvc_ioc_ops);
+		xvc_char_ioc_dev.owner = THIS_MODULE;
+		status = cdev_add(&xvc_char_ioc_dev, xvc_ioc_dev_region, CONFIG_COUNT);
+		if (status != 0) {
+			xil_xvc_cleanup();
+			dev_err(&pdev->dev, "unable to add char device\n");
+			return status;
+		}
+	}
+
+	for (i = 0; i < CONFIG_COUNT; ++i) {
+		if (db_ptrs[i] == NULL) {
+#ifndef GET_DB_BY_RES
+			const char *name = db_configs[i].name;
+			unsigned long db_addr = db_configs[i].base_addr;
+			unsigned long db_size = db_configs[i].size;
+#else
+			const char *name = NULL;
+			unsigned long db_addr = 0;
+			unsigned long db_size = 0;
+#endif
+
+			if (name && name[0]) {
+				sprintf(ioc_device_name, "%s_%s", XVC_DRIVER_NAME, name);
+			} else if (use_index) {
+				sprintf(ioc_device_name, "%s_%d", XVC_DRIVER_NAME, i);
+			} else {
+				sprintf(ioc_device_name, "%s", XVC_DRIVER_NAME);
+			}
+
+			ioc_device_number = MKDEV(MAJOR(xvc_ioc_dev_region), MINOR(xvc_ioc_dev_region) + i);
+
+			xvc_ioc_device = device_create(xvc_dev_class, NULL, ioc_device_number, NULL, ioc_device_name);
+			if (IS_ERR(xvc_ioc_device)) {
+				//printk(KERN_WARNING LOG_PREFIX "Failed to create device %s", ioc_device_name);
+				printk(KERN_WARNING "Failed to create device %s", ioc_device_name);
+				xil_xvc_cleanup();
+				dev_err(&pdev->dev, "unable to create the device\n");
+				return status;
+			} else {
+				//printk(KERN_INFO LOG_PREFIX "Created device %s", ioc_device_name);
+				printk(KERN_INFO "Created device %s", ioc_device_name);
+			}
+
+#ifndef GET_DB_BY_RES
+			//db_ptrs[i] = ioremap_nocache(db_addr, db_size);
+			db_ptrs[i] = ioremap(db_addr, db_size);
+			//db_ptrs[i] = ioremap_cache(db_addr, db_size);
+#else
+			db_res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
+			if (db_res) {
+				db_addr = db_res->start;
+				db_size = resource_size(db_res);
+			}
+			db_ptrs[i] = devm_ioremap_resource(&pdev->dev, db_res);
+#endif
+			if (!db_ptrs[i] || IS_ERR(db_ptrs[i])) {
+				//printk(KERN_ERR LOG_PREFIX "Failed to remap debug bridge memory at offset 0x%lX, size %lu", db_addr, db_size);
+				printk(KERN_ERR "Failed to remap debug bridge memory at offset 0x%lX, size %lu", db_addr, db_size);
+				return -ENOMEM;
+			} else {
+				//printk(KERN_INFO LOG_PREFIX "Mapped debug bridge at offset 0x%lX, size 0x%lX", db_addr, db_size);
+				printk(KERN_INFO "Mapped debug bridge at offset 0x%lX, size 0x%lX", db_addr, db_size);
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int remove(struct platform_device* pdev) {
+	int i;
+	dev_t ioc_device_number;
+	if (pdev) {
+		for (i = 0; i < CONFIG_COUNT; ++i) {
+			if (db_ptrs[i]) {
+#ifndef GET_DB_BY_RES
+				unsigned long db_addr = db_configs[i].base_addr;
+				unsigned long db_size = db_configs[i].size;
+#else
+				unsigned long db_addr = 0;
+				unsigned long db_size = 0;
+				if (db_res) {
+					db_addr = db_res->start;
+					db_size = resource_size(db_res);
+				}
+#endif
+
+				//printk(KERN_INFO LOG_PREFIX "Unmapping debug bridge at offset 0x%lX, size %lu", db_addr, db_size);
+				printk(KERN_INFO "Unmapping debug bridge at offset 0x%lX, size %lu", db_addr, db_size);
+#ifndef GET_DB_BY_RES
+				iounmap(db_ptrs[i]);
+#else
+				// devm_ioremap_resource is managed by the kernel and undone on driver detach.
+#endif
+				db_ptrs[i] = NULL;
+
+				ioc_device_number = MKDEV(MAJOR(xvc_ioc_dev_region), MINOR(xvc_ioc_dev_region) + i);
+				device_destroy(xvc_dev_class, ioc_device_number);
+				//printk(KERN_INFO LOG_PREFIX "Destroyed device number %u (user config %i)", ioc_device_number, i);
+				printk(KERN_INFO "Destroyed device number %u (user config %i)", ioc_device_number, i);
+			}
+		}
+	}
+
+	return 0;
+}
+
+static const struct of_device_id xvc_of_ids[] = {
+	{ .compatible = DEBUG_BRIDGE_COMPAT_STRING, },
+	{}
+};
+
+static struct platform_driver xil_xvc_plat_driver = {
+	.driver = {
+		.name = XVC_DRIVER_NAME,
+		.owner = THIS_MODULE,
+		.of_match_table = xvc_of_ids,
+	},
+	.probe = probe,
+	.remove = remove,
+};
+
+// --------------------------
+// --------------------------
+// Driver initialization code
+// --------------------------
+// --------------------------
+
+static int __init xil_xvc_init(void) {
+	int err = 0;
+
+	//printk(KERN_INFO LOG_PREFIX "Starting...\n");
+	printk(KERN_INFO "Starting...\n");
+
+	// Register the character packet device major and minor numbers
+	err = alloc_chrdev_region(&xvc_ioc_dev_region, 0, CONFIG_COUNT, XVC_DRIVER_NAME);
+	if (err != 0) {
+		xil_xvc_cleanup();
+		//printk(KERN_ERR LOG_PREFIX "unable to get char device region\n");
+		printk(KERN_ERR "unable to get char device region\n");
+		return err;
+	}
+
+	memset(db_ptrs, 0, sizeof(*db_ptrs));
+
+	return platform_driver_register(&xil_xvc_plat_driver);
+}
+
+static void __exit xil_xvc_exit(void) {
+	platform_driver_unregister(&xil_xvc_plat_driver);
+	xil_xvc_cleanup();
+}
+
+module_init(xil_xvc_init);
+module_exit(xil_xvc_exit);
diff --git a/drivers/x2o/xilinx-xvc-driver/xvc_ioctl.h b/drivers/x2o/xilinx-xvc-driver/xvc_ioctl.h
new file mode 100644
index 000000000000..2e1a44fabce6
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xvc_ioctl.h
@@ -0,0 +1,44 @@
+/*
+ * Xilinx XVC Driver
+ * Copyright (C) 2019 Xilinx Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#ifndef _XVC_IOCTL_H
+#define _XVC_IOCTL_H
+
+#include <linux/ioctl.h>
+
+#define XIL_XVC_MAGIC 0x58564344  // "XVCD"
+
+struct xil_xvc_ioc {
+	unsigned opcode;
+	unsigned length;
+	unsigned char* tms_buf;
+	unsigned char* tdi_buf;
+	unsigned char* tdo_buf;
+};
+
+struct xil_xvc_properties {
+    unsigned long debug_bridge_base_addr;
+    unsigned long debug_bridge_size;
+    char debug_bridge_compat_string[64];
+};
+
+#define XDMA_IOCXVC      _IOWR(XIL_XVC_MAGIC, 1, struct xil_xvc_ioc)
+#define XDMA_RDXVC_PROPS _IOR(XIL_XVC_MAGIC, 2, struct xil_xvc_properties)
+
+#endif /* _XVC_IOCTL_H */
diff --git a/drivers/x2o/xilinx-xvc-driver/xvc_user_config.h b/drivers/x2o/xilinx-xvc-driver/xvc_user_config.h
new file mode 100644
index 000000000000..5022cdfd447e
--- /dev/null
+++ b/drivers/x2o/xilinx-xvc-driver/xvc_user_config.h
@@ -0,0 +1,95 @@
+/*
+ * Xilinx XVC Driver
+ * Copyright (C) 2019 Xilinx Corporation
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version 2
+ * of the License, or (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ */
+
+#ifndef _XVC_USER_CONFIG_H
+#define _XVC_USER_CONFIG_H
+
+// debug bridge configuration
+struct db_config {
+    const char* name;
+    unsigned long base_addr;
+    unsigned long size;
+};
+
+/*
+ * Modify the macros and structure below with customizations
+ * for the driver, if desired.
+ *
+ * XVC_DRIVER_NAME            - name of the driver and character files
+ * DEBUG_BRIDGE_COMPAT_STRING - debug_bridge ".compatible" entry in device tree
+ *
+ * name      - alias to append to character file name
+ * base_addr - debug_bridge base address from device tree
+ * size      - debug_bridge size from device tree
+ */
+#define XVC_DRIVER_NAME "xilinx_xvc_driver"
+#define DEBUG_BRIDGE_COMPAT_STRING "xlnx,xvc"
+
+static const struct db_config db_configs[] = {
+    /////////////////////////////////////////////////////////
+    //  The single debug tree entry below with an empty 
+    //  name modifier will create a character file called:
+    //
+    //   /dev/xilinx_xvc_driver
+    //
+    /////////////////////////////////////////////////////////
+    {
+        .name = "",
+        .base_addr = 0x0443c00000,
+        .size = 0x10000,
+    },
+    {
+        .name = "",
+        .base_addr = 0x0443c10000,
+        .size = 0x10000,
+    },
+    /////////////////////////////////////////////////////////
+    //  For two debug trees in the same driver, you can 
+    //  uncomment and modify the entries below.  If names are
+    //  empty, only the index will be appended to the
+    //  character file:
+    //   /dev/xilinx_xvc_driver_0
+    //   /dev/xilinx_xvc_driver_1
+    //
+    //  In this example, since the names are not empty, the
+    //  names "tree0" and "tree1" are appended to the
+    //  character files as follows:
+    //
+    //   /dev/xilinx_xvc_driver_tree0
+    //   /dev/xilinx_xvc_driver_tree1
+    //
+    /////////////////////////////////////////////////////////
+    //
+    /*
+    {
+        .name = "tree0",
+        .base_addr = 0x90020000,
+        .size = 0x10000,
+    },
+    {
+        .name = "tree1",
+        .base_addr = 0x90030000,
+        .size = 0x10000,
+    },
+    */
+};
+
+#define CONFIG_COUNT (sizeof(db_configs) / sizeof(*db_configs))
+
+#endif /* _XVC_USER_CONFIG_H */
